{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import _keras\n",
    "\n",
    "from tensorboard_utils import *\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "from dataset_utils import split_dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import os, stat\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from models import *\n",
    "from losses import rgb_diff\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_readonly(func, path, _):\n",
    "    \"Clear the readonly bit and reattempt the removal\"\n",
    "    os.chmod(path, stat.S_IWRITE)\n",
    "    func(path)\n",
    "\n",
    "print(\"Loading dataset\")\n",
    "split0, split1 = tfds.even_splits('all', n=2)\n",
    "ds_cover = tfds.load('stl10', split=split0 , shuffle_files=True)\n",
    "ds_hidden = tfds.load('stl10', split=split1 , shuffle_files=True)\n",
    "print(\"Loaded dataset\")\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "strategy = tf.distribute.MirroredStrategy(devices=None)\n",
    "GLOBAL_BATCH_SIZE = strategy.num_replicas_in_sync * BATCH_SIZE\n",
    "\n",
    "print(f'Number of devices: {strategy.num_replicas_in_sync}')\n",
    "\n",
    "[ds_cover_train,  ds_cover_val , ds_cover_test] = split_dataset(ds_cover)\n",
    "[ds_hidden_train, ds_hidden_val, ds_hidden_test] = split_dataset(ds_hidden)\n",
    "\n",
    "\n",
    "print(f\"Length of clear train set: {len(ds_cover_train)}, validation: {len(ds_cover_val)}, and test: {len(ds_cover_test)}\")\n",
    "print(f\"Length of hidden train set: {len(ds_hidden_train)}, validation: {len(ds_hidden_val)}, and test: {len(ds_hidden_test)}\")\n",
    "\n",
    "\n",
    "NUM_TRAIN_SAMPLES = len(ds_cover_train)\n",
    "NUM_VAL_SAMPLES = len(ds_hidden_val)\n",
    "TRAIN_STEPS = ceil(NUM_TRAIN_SAMPLES / GLOBAL_BATCH_SIZE)\n",
    "TEST_STEPS = ceil(NUM_VAL_SAMPLES / GLOBAL_BATCH_SIZE)\n",
    "\n",
    "def normalize(ds):\n",
    "    # print(image)\n",
    "    image_ds = (tf.cast(ds['image'],tf.float32)) / 255.0\n",
    "    return image_ds\n",
    "\n",
    "ds_cover_train = ds_cover_train.map(normalize, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "ds_cover_train = ds_cover_train.cache()\n",
    "ds_hidden_train = ds_hidden_train.map(normalize, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "ds_hidden_train = ds_hidden_train.cache()\n",
    "\n",
    "ds_train = tf.data.Dataset.zip((ds_cover_train, ds_hidden_train)).batch(GLOBAL_BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ds_hidden_val = ds_hidden_val.map(normalize, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "ds_hidden_val = ds_hidden_val.cache()\n",
    "ds_cover_val = ds_cover_val.map(normalize, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "ds_cover_val = ds_cover_val.cache()\n",
    "\n",
    "ds_val = tf.data.Dataset.zip((ds_cover_val, ds_hidden_val)).batch(GLOBAL_BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ds_hidden_test = ds_hidden_test.map(normalize, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "ds_hidden_test = ds_hidden_test.cache()\n",
    "ds_cover_test = ds_cover_test.map(normalize, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "ds_cover_test = ds_cover_test.cache()\n",
    "\n",
    "ds_test = tf.data.Dataset.zip((ds_cover_test, ds_hidden_test)).batch(GLOBAL_BATCH_SIZE, ).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "plot_ds = tf.data.Dataset.zip(\n",
    "    (ds_cover_test.take(5).batch(1), ds_hidden_test.take(5).batch(1)))\n",
    "\n",
    "# create distributed datasets\n",
    "ds_train = strategy.experimental_distribute_dataset(ds_train)\n",
    "ds_val = strategy.experimental_distribute_dataset(ds_val)\n",
    "ds_test = strategy.experimental_distribute_dataset(ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the training steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the model within strategy scope\n",
    "input_shape = (96, 96, 3)  # Adjust input size as needed\n",
    "with strategy.scope():\n",
    "    enc_dec_model = create_encoder_decoder_model(input_shape)\n",
    "\n",
    "    enc_dec_model.summary()\n",
    "\n",
    "    enc_dec_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4,\n",
    "                                            beta_1=0.5,\n",
    "                                            beta_2=0.9)\n",
    "\n",
    "    checkpoint_dir = './training_checkpoints'\n",
    "    checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "    checkpoint = tf.train.Checkpoint(encoder_optimizer=enc_dec_optimizer,\n",
    "                                    decoder_encoder=enc_dec_model)\n",
    "\n",
    "\n",
    "\n",
    "def reduce_mean(per_sample_loss):\n",
    "    \"\"\" return the global mean of per-sample loss \"\"\"\n",
    "    return tf.reduce_sum(per_sample_loss) / GLOBAL_BATCH_SIZE\n",
    "\n",
    "enc_weigh = 0.4\n",
    "dec_weigh = 0.6\n",
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(cover_imgs, hidden_imgs):\n",
    "    result = {}\n",
    "    with tf.GradientTape() as tape:\n",
    "        [encoded_imgs, decoded_imgs] = enc_dec_model([cover_imgs, hidden_imgs], training=True)\n",
    "\n",
    "        enc_loss = reduce_mean(rgb_diff(encoded_imgs, cover_imgs))\n",
    "        dec_loss = reduce_mean(rgb_diff(decoded_imgs, hidden_imgs))\n",
    "\n",
    "        total_loss = enc_weigh * enc_loss + dec_weigh * dec_loss\n",
    "\n",
    "\n",
    "    result.update({\n",
    "    'train/loss_enc': enc_loss,\n",
    "    'train/loss_dec': dec_loss,\n",
    "    'train/total_loss': total_loss,\n",
    "    })\n",
    "\n",
    "    enc_dec_optimizer.minimize(loss=total_loss, var_list=enc_dec_model.trainable_variables, tape = tape)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def reduce_dict(d: dict):\n",
    "  \"\"\" inplace reduction of items in dictionary d \"\"\"\n",
    "  return {\n",
    "        k: strategy.reduce(tf.distribute.ReduceOp.SUM, v, axis=None)\n",
    "        for k, v in d.items()\n",
    "  }\n",
    "\n",
    "@tf.function\n",
    "def distributed_train_step(x, y):\n",
    "    results = strategy.run(train_step, args=(x, y))\n",
    "    results = reduce_dict(results)\n",
    "    return results\n",
    "\n",
    "def test_step(cover_val, hidden_val):\n",
    "    result = {}\n",
    "    [encoded_imgs, decoded_imgs] = enc_dec_model([cover_val, hidden_val], training=False)\n",
    "\n",
    "    enc_loss = reduce_mean(rgb_diff(encoded_imgs, cover_val))\n",
    "    dec_loss = reduce_mean(rgb_diff(decoded_imgs, hidden_val))\n",
    "\n",
    "    total_loss = enc_weigh * enc_loss + dec_weigh * dec_loss\n",
    "\n",
    "    result.update({\n",
    "    'val/loss_enc': enc_loss,\n",
    "    'val/loss_dec': dec_loss,\n",
    "    'val/total_loss': total_loss,\n",
    "    })\n",
    "\n",
    "    return result\n",
    "\n",
    "@tf.function\n",
    "def distributed_test_step(x, y):\n",
    "    results = strategy.run(test_step, args=(x, y))\n",
    "    results = reduce_dict(results)\n",
    "    return results\n",
    "\n",
    "def train(ds, summary, epoch: int):\n",
    "    results = {}\n",
    "    for cover_batch, hidden_batch in tqdm(ds, total=TRAIN_STEPS):\n",
    "        result = distributed_train_step(cover_batch, hidden_batch)\n",
    "        append_dict(results, result)\n",
    "    for key, value in results.items():\n",
    "        results[key] = tf.reduce_mean(value)\n",
    "        summary.scalar(key, results[key], step=epoch, training=True)\n",
    "    return results\n",
    "\n",
    "\n",
    "def test(ds, summary, epoch: int):\n",
    "    results = {}\n",
    "    for cover_batch, hidden_batch in tqdm(ds, total=TEST_STEPS):\n",
    "        result = distributed_test_step(cover_batch, hidden_batch)\n",
    "        append_dict(results, result)\n",
    "    for key, value in results.items():\n",
    "        results[key] = tf.reduce_mean(value)\n",
    "        summary.scalar(key, results[key], step=epoch, training=False)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_cycle(ds, summary, epoch: int):\n",
    "    \"\"\" plot X -> G(X) -> F(G(X)) and Y -> F(Y) -> G(F(Y)) \"\"\"\n",
    "    samples = {}\n",
    "    for cover_img, hidden_img in ds:\n",
    "        [encoded_img, decoded_img] = enc_dec_model([cover_img, hidden_img], training=False)\n",
    "        append_dict(dict1=samples,\n",
    "                    dict2={\n",
    "                        'cover_img': cover_img,\n",
    "                        'hidden_img': hidden_img,\n",
    "                        'encoded_img': encoded_img,\n",
    "                        'decoded_img': decoded_img\n",
    "                    })\n",
    "    for key, images in samples.items():\n",
    "        # scale images back to [0, 255]\n",
    "        images = tf.concat(images, axis=0).numpy()\n",
    "        images = (images * 255.0).astype(np.uint8)\n",
    "        samples[key] = images\n",
    "    summary.image_cycle(\n",
    "        tag=f'Encoding Cycle',\n",
    "        images=[samples['cover_img'], samples['hidden_img'], samples['encoded_img'], samples['decoded_img']],\n",
    "        labels=['cover_img', 'hidden_img', 'encoded_img', 'decoded_img'],\n",
    "        step=epoch,\n",
    "        training=False)\n",
    "\n",
    "\n",
    "OUTPUT_DIR = 'runs'  # directory to store checkpoint and TensorBoard summary\n",
    "\n",
    "if os.path.exists(OUTPUT_DIR):\n",
    "    # Clear out any prior log data.\n",
    "    shutil.rmtree(OUTPUT_DIR, onerror=remove_readonly)\n",
    "os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "summary = Summary(output_dir=OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  [predictions_cov, predictions_hid] = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions_cov[i, :, :, 0] * 255.0, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_PATH = \"./ckpt\"\n",
    "# ckpt_path = OUTPUT_DIR+'checkpoint.data-00000-of-00001'\n",
    "# checkpoint.restore(OUTPUT_DIR+ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1\n",
    "checkpoint_manager = tf.train.CheckpointManager(checkpoint, CKPT_PATH, max_to_keep=3)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f'Epoch {epoch + 1:03d}/{NUM_EPOCHS:03d}')\n",
    "    start = time.time()\n",
    "    train_results = train(ds_train, summary, epoch)\n",
    "    test_results = test(ds_val, summary, epoch)\n",
    "    end = time.time()\n",
    "\n",
    "    # print(\"train_results: \\n{}\", train_results)\n",
    "    # print(\"test_results: \\n{}\", test_results)\n",
    "\n",
    "    print(f'train/loss_enc: {train_results[\"train/loss_enc\"]:.04f}\\t\\t'\n",
    "            f'train/loss_dec: {train_results[\"train/loss_dec\"]:.04f}\\n'\n",
    "            f'train/total_loss: {train_results[\"train/total_loss\"]:.04f}\\n'\n",
    "            f'val/loss_enc: {test_results[\"val/loss_enc\"]:.04f}\\t\\t'\n",
    "            f'val/loss_dec: {test_results[\"val/loss_dec\"]:.04f}\\n'\n",
    "            f'val/total_loss: {test_results[\"val/total_loss\"]:.04f}\\n'\n",
    "            f'Elapse: {end - start:.02f}s\\n')\n",
    "\n",
    "    if (epoch + 1) % 5 == 0 or epoch == NUM_EPOCHS - 1:\n",
    "        save_path = checkpoint_manager.save()\n",
    "        plot_cycle(plot_ds, summary, epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
